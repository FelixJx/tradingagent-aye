from flask import Flask, request, jsonify, render_template
import os
import sys
import json
import traceback
from datetime import datetime, timedelta
import time
import threading

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥çœŸå®æ•°æ®é›†æˆæ¨¡å—
try:
    from real_data_integration import get_real_stock_data, get_real_news_analysis, get_real_llm_analysis
    REAL_DATA_AVAILABLE = True
    print("âœ… Real data integration loaded successfully")
except ImportError as e:
    REAL_DATA_AVAILABLE = False
    print(f"âŒ Real data integration FAILED to load: {e}")
    print(f"âŒ This means the system will use mock data even in production!")
except Exception as e:
    REAL_DATA_AVAILABLE = False
    print(f"âŒ Unexpected error loading real data integration: {type(e).__name__}: {e}")

# å¯¼å…¥é…ç½®ç®¡ç†ï¼Œä¼˜å…ˆä½¿ç”¨å®Œæ•´é…ç½®
config = None
try:
    from config import get_config
    config = get_config()
    print("âœ… Using full configuration with LangChain support")
except Exception as e:
    print(f"âš ï¸ Full config import failed: {e}")
    try:
        from config_simple import get_simple_config
        config = get_simple_config()
        print("ğŸ“¦ Using simplified configuration")
    except Exception as e2:
        print(f"âš ï¸ Simple config also failed: {e2}")
        print("ğŸ”§ Using direct environment variables")
        
        # åˆ›å»ºä¸€ä¸ªåŸºç¡€é…ç½®å¯¹è±¡
        class BasicConfig:
            @property
            def tushare_token(self):
                return os.getenv('TUSHARE_TOKEN')
            @property
            def dashscope_api_key(self):
                return os.getenv('DASHSCOPE_API_KEY')
            @property
            def tavily_api_key(self):
                return os.getenv('TAVILY_API_KEY')
        
        config = BasicConfig()

app = Flask(__name__)

# å…¨å±€å˜é‡
trading_agent = None
analysis_cache = {}

# æ£€æµ‹é«˜çº§åŠŸèƒ½å¯ç”¨æ€§
def check_advanced_features():
    """æ£€æµ‹é«˜çº§åŠŸèƒ½æ˜¯å¦å¯ç”¨"""
    features = {
        'langchain': False,
        'akshare': False,
        'pandas': False,
        'tushare': False,
        'dashscope': False,
        'tavily': False,
        'enhanced_agent': False,
        'real_time_data': False,
        'news_search': False,
        'enhanced_llm': False
    }
    
    try:
        import langchain
        features['langchain'] = True
        print("âœ… LangChain available")
    except ImportError:
        print("âŒ LangChain not available")
    
    try:
        import akshare
        features['akshare'] = True
        print("âœ… AKShare available")
    except ImportError:
        print("âŒ AKShare not available")
    
    try:
        import pandas
        features['pandas'] = True
        print("âœ… Pandas available")
    except ImportError:
        print("âŒ Pandas not available")
    
    try:
        import tushare
        features['tushare'] = True
        print("âœ… Tushare available")
    except ImportError:
        print("âŒ Tushare not available")
    
    try:
        import dashscope
        features['dashscope'] = True
        print("âœ… DashScope available")
    except ImportError:
        print("âŒ DashScope not available")
    
    try:
        from tavily import TavilyClient
        features['tavily'] = True
        print("âœ… Tavily available")
    except ImportError:
        print("âŒ Tavily not available")
    
    try:
        from enhanced_agent_architecture import EnhancedTradingSystem
        features['enhanced_agent'] = True
        print("âœ… Enhanced Agent Architecture available")
    except ImportError as e:
        print(f"âŒ Enhanced Agent Architecture not available: {e}")
    
    try:
        from real_time_data_service import get_data_service
        features['real_time_data'] = True
        print("âœ… Real-time Data Service available")
    except ImportError:
        print("âŒ Real-time Data Service not available")
    
    try:
        from news_search_service import get_news_service
        features['news_search'] = True
        print("âœ… News Search Service available")
    except ImportError:
        print("âŒ News Search Service not available")
    
    try:
        from enhanced_llm_service import get_llm_service
        features['enhanced_llm'] = True
        print("âœ… Enhanced LLM Service available")
    except ImportError:
        print("âŒ Enhanced LLM Service not available")
    
    return features

# åˆå§‹åŒ–æ—¶æ£€æŸ¥åŠŸèƒ½
AVAILABLE_FEATURES = check_advanced_features()

def get_stock_data(symbol):
    """è·å–è‚¡ç¥¨æ•°æ® - ä¼˜å…ˆä½¿ç”¨çœŸå®APIæ•°æ®"""
    try:
        # å¼ºåˆ¶æ£€æŸ¥ç¯å¢ƒå˜é‡ - ç›´æ¥ä»os.getenvè·å–ï¼Œç¡®ä¿å‡†ç¡®æ€§
        flask_env = os.getenv('FLASK_ENV', 'development')
        config_env = getattr(config, 'flask_env', 'unknown') if config else 'no_config'
        
        print(f"ğŸ”§ Environment check: OS_ENV={flask_env}, CONFIG_ENV={config_env}, REAL_DATA={REAL_DATA_AVAILABLE}")
        
        # å¼ºåˆ¶åœ¨Renderéƒ¨ç½²ç¯å¢ƒä¸­ä½¿ç”¨çœŸå®æ•°æ®ï¼ˆä¸´æ—¶ä¿®å¤ï¼‰
        is_render_deployment = os.getenv('RENDER') or os.getenv('RENDER_SERVICE_ID') or 'render' in os.getcwd().lower()
        should_use_real_data = REAL_DATA_AVAILABLE and (flask_env == 'production' or is_render_deployment)
        
        if should_use_real_data:
            print(f"ğŸ”„ Fetching REAL stock data for {symbol} (env: {flask_env}, render: {is_render_deployment})")
            return get_real_stock_data(symbol)
        
        # å¼€å‘ç¯å¢ƒæˆ–APIä¸å¯ç”¨æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        print(f"âš ï¸ Using MOCK data for {symbol} (env: {flask_env}, real_data: {REAL_DATA_AVAILABLE})")
        base_price = 100 + (hash(symbol) % 50)
        
        return {
            'symbol': symbol,
            'name': get_stock_name(symbol),
            'current_price': round(base_price + (hash(symbol + str(datetime.now().day)) % 20 - 10), 2),
            'open_price': round(base_price + (hash(symbol + 'open') % 15 - 7), 2),
            'high_price': round(base_price + (hash(symbol + 'high') % 25), 2),
            'low_price': round(base_price - (hash(symbol + 'low') % 15), 2),
            'volume': (hash(symbol + 'vol') % 1000000) + 100000,
            'turnover': round((hash(symbol + 'turn') % 100) / 10, 2),
            'pe_ratio': round(15 + (hash(symbol + 'pe') % 30), 2),
            'pb_ratio': round(1 + (hash(symbol + 'pb') % 50) / 10, 2),
            'market_cap': (hash(symbol + 'cap') % 5000) + 1000,
            'data_source': 'mock'
        }
    except Exception as e:
        print(f"âŒ Stock data error: {e}")
        return {'error': f'æ•°æ®è·å–å¤±è´¥: {str(e)}'}

def get_stock_name(symbol):
    """è·å–è‚¡ç¥¨åç§°"""
    names = {
        '000001.SZ': 'å¹³å®‰é“¶è¡Œ',
        '000002.SZ': 'ä¸‡ç§‘A',
        '600036.SH': 'æ‹›å•†é“¶è¡Œ',
        '600519.SH': 'è´µå·èŒ…å°',
        '000858.SZ': 'äº”ç²®æ¶²',
        '002415.SZ': 'æµ·åº·å¨è§†',
        '300059.SZ': 'ä¸œæ–¹è´¢å¯Œ'
    }
    return names.get(symbol, f'è‚¡ç¥¨{symbol.split(".")[0]}')

def get_news_analysis(symbol):
    """è·å–æ–°é—»åˆ†æ - ä¼˜å…ˆä½¿ç”¨çœŸå®APIæ•°æ®"""
    try:
        # ç›´æ¥æ£€æŸ¥ç¯å¢ƒå˜é‡
        flask_env = os.getenv('FLASK_ENV', 'development')
        
        # å¼ºåˆ¶åœ¨Renderéƒ¨ç½²ç¯å¢ƒä¸­ä½¿ç”¨çœŸå®æ•°æ®
        is_render_deployment = os.getenv('RENDER') or os.getenv('RENDER_SERVICE_ID') or 'render' in os.getcwd().lower()
        should_use_real_data = REAL_DATA_AVAILABLE and (flask_env == 'production' or is_render_deployment)
        
        if should_use_real_data:
            print(f"ğŸ”„ Fetching REAL news data for {symbol}")
            return get_real_news_analysis(symbol)
        
        # å¼€å‘ç¯å¢ƒæˆ–APIä¸å¯ç”¨æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        print(f"âš ï¸ Using MOCK news data for {symbol} (env: {flask_env}, real_data: {REAL_DATA_AVAILABLE})")
        sentiment_score = round((hash(symbol + 'news') % 200 - 100) / 100, 2)
        news_count = hash(symbol + 'count') % 20 + 5
        
        sentiments = ['ç§¯æ', 'ä¸­æ€§', 'æ¶ˆæ']
        sentiment_text = sentiments[1] if abs(sentiment_score) < 0.3 else (sentiments[0] if sentiment_score > 0 else sentiments[2])
        
        return {
            'sentiment_score': sentiment_score,
            'sentiment_text': sentiment_text,
            'news_count': news_count,
            'summary': f'æ ¹æ®æœ€è¿‘{news_count}æ¡æ–°é—»åˆ†æï¼Œå¸‚åœºå¯¹{get_stock_name(symbol)}çš„æƒ…æ„Ÿåå‘{sentiment_text}',
            'key_news': [
                f'{get_stock_name(symbol)}å‘å¸ƒæœ€æ–°è´¢æŠ¥ï¼Œä¸šç»©è¶…é¢„æœŸ',
                f'æœºæ„è°ƒç ”æ˜¾ç¤ºå¯¹{get_stock_name(symbol)}å‰æ™¯çœ‹å¥½',
                f'{get_stock_name(symbol)}è·å¾—é‡è¦åˆä½œé¡¹ç›®'
            ][:news_count//3 + 1],
            'data_source': 'mock'
        }
    except Exception as e:
        print(f"âŒ News analysis error: {e}")
        return {'error': f'æ–°é—»åˆ†æå¤±è´¥: {str(e)}'}

def get_technical_indicators(symbol):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
    try:
        base = hash(symbol) % 100
        
        return {
            'RSI': round(30 + (base % 40), 2),
            'MACD': round((base % 20 - 10) / 10, 3),
            'KDJ_K': round(20 + (base % 60), 2),
            'KDJ_D': round(25 + (base % 50), 2),
            'KDJ_J': round(15 + (base % 70), 2),
            'MA5': round(95 + (base % 20), 2),
            'MA10': round(93 + (base % 25), 2),
            'MA20': round(90 + (base % 30), 2),
            'MA60': round(85 + (base % 35), 2),
            'BOLL_UPPER': round(105 + (base % 15), 2),
            'BOLL_MIDDLE': round(100 + (base % 10), 2),
            'BOLL_LOWER': round(95 + (base % 8), 2)
        }
    except Exception as e:
        return {'error': f'æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}'}

def multi_agent_analysis(symbol, stock_data, news_data, technical_data):
    """å¤šæ™ºèƒ½ä½“åˆ†æ - å¢å¼ºç‰ˆLLMé©±åŠ¨åˆ†æ"""
    try:
        # ç›´æ¥æ£€æŸ¥ç¯å¢ƒå˜é‡
        flask_env = os.getenv('FLASK_ENV', 'development')
        is_render_deployment = os.getenv('RENDER') or os.getenv('RENDER_SERVICE_ID') or 'render' in os.getcwd().lower()
        use_llm = REAL_DATA_AVAILABLE and (flask_env == 'production' or is_render_deployment)
        
        print(f"ğŸ¤– Running multi-agent analysis for {symbol} (ENV: {flask_env}, LLM: {use_llm})")
        
        agents = {
            'åŸºæœ¬é¢åˆ†æå¸ˆ': analyze_fundamentals(symbol, stock_data, use_llm),
            'æŠ€æœ¯åˆ†æå¸ˆ': analyze_technical(symbol, technical_data, use_llm),
            'æƒ…æ„Ÿåˆ†æå¸ˆ': analyze_sentiment(symbol, news_data, use_llm),
            'é£é™©æ§åˆ¶å¸ˆ': analyze_risk(symbol, stock_data, use_llm),
            'é‡åŒ–åˆ†æå¸ˆ': analyze_quantitative(symbol, stock_data, technical_data, use_llm)
        }
        
        # å¦‚æœä½¿ç”¨LLMï¼Œè¿˜éœ€è¦ç”Ÿæˆæ™ºèƒ½ä½“åå•†ç»“æœ
        if use_llm:
            agents['ç»¼åˆå†³ç­–å¸ˆ'] = synthesize_agent_decisions(symbol, agents, stock_data, news_data, technical_data)
        
        return agents
    except Exception as e:
        print(f"âŒ Multi-agent analysis error: {e}")
        return {'error': f'å¤šæ™ºèƒ½ä½“åˆ†æå¤±è´¥: {str(e)}'}

def analyze_fundamentals(symbol, data, use_llm=False):
    """åŸºæœ¬é¢åˆ†æ - æ”¯æŒLLMæ·±åº¦åˆ†æ"""
    try:
        if use_llm:
            # ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åŸºæœ¬é¢åˆ†æ
            prompt = f"""
ä½œä¸ºä¸“ä¸šçš„åŸºæœ¬é¢åˆ†æå¸ˆï¼Œè¯·å¯¹è‚¡ç¥¨ {symbol} ({data.get('name', 'æœªçŸ¥')}) è¿›è¡Œæ·±åº¦åŸºæœ¬é¢åˆ†æï¼š

è´¢åŠ¡æ•°æ®ï¼š
- å¸‚ç›ˆç‡(PE): {data.get('pe_ratio', 'æœªçŸ¥')}
- å¸‚å‡€ç‡(PB): {data.get('pb_ratio', 'æœªçŸ¥')}
- å¸‚å€¼: {data.get('market_cap', 'æœªçŸ¥')}äº¿å…ƒ
- å½“å‰ä»·æ ¼: {data.get('current_price', 'æœªçŸ¥')}å…ƒ
- æ¢æ‰‹ç‡: {data.get('turnover', 'æœªçŸ¥')}%

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
1. ä¼°å€¼æ°´å¹³è¯„ä¼°ï¼ˆPEã€PBæ˜¯å¦åˆç†ï¼‰
2. è¡Œä¸šå¯¹æ¯”åˆ†æ
3. è´¢åŠ¡å¥åº·åº¦åˆ¤æ–­
4. æŠ•èµ„ä»·å€¼è¯„ä¼°
5. å…·ä½“ä¹°å…¥/æŒæœ‰/å–å‡ºå»ºè®®

è¯·æä¾›ä¸“ä¸šä¸”ç®€æ´çš„åˆ†æç»“è®ºï¼ˆ200å­—ä»¥å†…ï¼‰ã€‚
"""
            try:
                analysis = get_real_llm_analysis(prompt, {'stock_data': data})
                return f"ã€LLMæ·±åº¦åˆ†æã€‘{analysis}"
            except Exception as e:
                print(f"LLM fundamental analysis failed: {e}")
                # é™çº§åˆ°åŸºç¡€åˆ†æ
                pass
        
        # åŸºç¡€è§„åˆ™åˆ†æï¼ˆå¤‡ç”¨æˆ–å¼€å‘ç¯å¢ƒï¼‰
        pe = data.get('pe_ratio', 20)
        pb = data.get('pb_ratio', 2)
        
        if pe < 15 and pb < 1.5:
            return f'ã€åŸºç¡€åˆ†æã€‘ä¼°å€¼åä½ï¼ŒPE={pe}, PB={pb}ï¼Œå…·æœ‰æŠ•èµ„ä»·å€¼ã€‚å½“å‰ä»·æ ¼{data.get("current_price", "æœªçŸ¥")}å…ƒï¼Œå»ºè®®å…³æ³¨ã€‚'
        elif pe > 30 or pb > 3:
            return f'ã€åŸºç¡€åˆ†æã€‘ä¼°å€¼åé«˜ï¼ŒPE={pe}, PB={pb}ï¼Œå»ºè®®è°¨æ…ã€‚å½“å‰å¸‚å€¼{data.get("market_cap", "æœªçŸ¥")}äº¿ï¼Œéœ€è¦è§‚æœ›ã€‚'
        else:
            return f'ã€åŸºç¡€åˆ†æã€‘ä¼°å€¼åˆç†ï¼ŒPE={pe}, PB={pb}ï¼Œå¯é€‚é‡é…ç½®ã€‚ä»·æ ¼{data.get("current_price", "æœªçŸ¥")}å…ƒå±äºåˆç†åŒºé—´ã€‚'
    except Exception as e:
        return f'åŸºæœ¬é¢æ•°æ®åˆ†æå¼‚å¸¸: {str(e)}'

def analyze_technical(symbol, data, use_llm=False):
    """æŠ€æœ¯åˆ†æ - æ”¯æŒLLMæ·±åº¦åˆ†æ"""
    try:
        if use_llm:
            prompt = f"""
ä½œä¸ºä¸“ä¸šæŠ€æœ¯åˆ†æå¸ˆï¼Œè¯·å¯¹è‚¡ç¥¨ {symbol} è¿›è¡ŒæŠ€æœ¯é¢åˆ†æï¼š

æŠ€æœ¯æŒ‡æ ‡ï¼š
- RSI: {data.get('RSI', 'æœªçŸ¥')}
- MACD: {data.get('MACD', 'æœªçŸ¥')}
- KDJ: K={data.get('KDJ_K', 'æœªçŸ¥')}, D={data.get('KDJ_D', 'æœªçŸ¥')}, J={data.get('KDJ_J', 'æœªçŸ¥')}
- å‡çº¿: MA5={data.get('MA5', 'æœªçŸ¥')}, MA20={data.get('MA20', 'æœªçŸ¥')}, MA60={data.get('MA60', 'æœªçŸ¥')}
- å¸ƒæ—å¸¦: ä¸Šè½¨={data.get('BOLL_UPPER', 'æœªçŸ¥')}, ä¸­è½¨={data.get('BOLL_MIDDLE', 'æœªçŸ¥')}, ä¸‹è½¨={data.get('BOLL_LOWER', 'æœªçŸ¥')}

è¯·åˆ†æï¼š
1. è¶…ä¹°/è¶…å–çŠ¶æ€
2. è¶‹åŠ¿æ–¹å‘åˆ¤æ–­
3. å…³é”®æ”¯æ’‘/é˜»åŠ›ä½
4. çŸ­æœŸäº¤æ˜“ä¿¡å·
5. å…·ä½“æ“ä½œå»ºè®®

è¯·æä¾›ç®€æ´çš„æŠ€æœ¯åˆ†æç»“è®ºï¼ˆ150å­—ä»¥å†…ï¼‰ã€‚
"""
            try:
                analysis = get_real_llm_analysis(prompt, {'technical_data': data})
                return f"ã€LLMæŠ€æœ¯åˆ†æã€‘{analysis}"
            except Exception as e:
                print(f"LLM technical analysis failed: {e}")
                pass
        
        # åŸºç¡€æŠ€æœ¯åˆ†æ
        rsi = data.get('RSI', 50)
        macd = data.get('MACD', 0)
        
        signals = []
        if rsi < 30:
            signals.append('RSIæ˜¾ç¤ºè¶…å–ï¼Œå¯èƒ½åå¼¹')
        elif rsi > 70:
            signals.append('RSIæ˜¾ç¤ºè¶…ä¹°ï¼Œæ³¨æ„é£é™©')
        else:
            signals.append(f'RSI={rsi}ï¼Œå¤„äºæ­£å¸¸åŒºé—´')
            
        if macd > 0:
            signals.append('MACDé‡‘å‰ï¼Œè¶‹åŠ¿å‘å¥½')
        else:
            signals.append('MACDæ­»å‰ï¼Œè¶‹åŠ¿è½¬å¼±')
            
        return f"ã€æŠ€æœ¯æŒ‡æ ‡ã€‘{'; '.join(signals)}" if signals else 'æŠ€æœ¯æŒ‡æ ‡ä¸­æ€§'
    except Exception as e:
        return f'æŠ€æœ¯åˆ†æå¼‚å¸¸: {str(e)}'

def analyze_sentiment(symbol, data, use_llm=False):
    """æƒ…æ„Ÿåˆ†æ - æ”¯æŒLLMæ·±åº¦åˆ†æ"""
    try:
        if use_llm:
            prompt = f"""
ä½œä¸ºå¸‚åœºæƒ…æ„Ÿåˆ†æå¸ˆï¼Œè¯·åˆ†æè‚¡ç¥¨ {symbol} çš„å¸‚åœºæƒ…æ„Ÿï¼š

æ–°é—»æ•°æ®ï¼š
- æƒ…æ„Ÿå¾—åˆ†: {data.get('sentiment_score', 'æœªçŸ¥')}
- æƒ…æ„Ÿå€¾å‘: {data.get('sentiment_text', 'æœªçŸ¥')}
- æ–°é—»æ•°é‡: {data.get('news_count', 'æœªçŸ¥')}æ¡
- å…³é”®æ–°é—»: {data.get('key_news', [])}

è¯·åˆ†æï¼š
1. å¸‚åœºæƒ…æ„Ÿå¯¹è‚¡ä»·çš„å½±å“
2. æŠ•èµ„è€…ä¿¡å¿ƒè¯„ä¼°
3. åª’ä½“å…³æ³¨åº¦åˆ†æ
4. çŸ­æœŸæƒ…æ„Ÿå˜åŒ–è¶‹åŠ¿
5. åŸºäºæƒ…æ„Ÿçš„äº¤æ˜“å»ºè®®

è¯·æä¾›ç®€æ´çš„æƒ…æ„Ÿåˆ†æç»“è®ºï¼ˆ120å­—ä»¥å†…ï¼‰ã€‚
"""
            try:
                analysis = get_real_llm_analysis(prompt, {'news_data': data})
                return f"ã€LLMæƒ…æ„Ÿåˆ†æã€‘{analysis}"
            except Exception as e:
                print(f"LLM sentiment analysis failed: {e}")
                pass
        
        # åŸºç¡€æƒ…æ„Ÿåˆ†æ
        score = data.get('sentiment_score', 0)
        news_count = data.get('news_count', 0)
        if score > 0.3:
            return f'ã€å¸‚åœºæƒ…æ„Ÿã€‘ç§¯æ(å¾—åˆ†:{score})ï¼Œ{news_count}æ¡æ–°é—»æ˜¾ç¤ºåˆ©å¥½ï¼Œå¸‚åœºçœ‹å¤šæƒ…ç»ªæµ“åš'
        elif score < -0.3:
            return f'ã€å¸‚åœºæƒ…æ„Ÿã€‘æ¶ˆæ(å¾—åˆ†:{score})ï¼Œ{news_count}æ¡æ–°é—»æ˜¾ç¤ºåˆ©ç©ºï¼Œéœ€è¦å…³æ³¨é£é™©'
        else:
            return f'ã€å¸‚åœºæƒ…æ„Ÿã€‘ä¸­æ€§(å¾—åˆ†:{score})ï¼Œ{news_count}æ¡æ–°é—»æ— æ˜æ˜¾å€¾å‘ï¼Œè§‚æœ›ä¸ºä¸»'
    except Exception as e:
        return f'æƒ…æ„Ÿåˆ†æå¼‚å¸¸: {str(e)}'

def analyze_risk(symbol, data, use_llm=False):
    """é£é™©åˆ†æ - æ”¯æŒLLMæ·±åº¦åˆ†æ"""
    try:
        if use_llm:
            prompt = f"""
ä½œä¸ºé£é™©æ§åˆ¶å¸ˆï¼Œè¯·å¯¹è‚¡ç¥¨ {symbol} è¿›è¡Œé£é™©è¯„ä¼°ï¼š

é£é™©æŒ‡æ ‡ï¼š
- æ¢æ‰‹ç‡: {data.get('turnover', 'æœªçŸ¥')}%
- å¸‚å€¼: {data.get('market_cap', 'æœªçŸ¥')}äº¿å…ƒ
- å½“å‰ä»·æ ¼: {data.get('current_price', 'æœªçŸ¥')}å…ƒ
- æˆäº¤é‡: {data.get('volume', 'æœªçŸ¥')}
- PEæ¯”ç‡: {data.get('pe_ratio', 'æœªçŸ¥')}

è¯·è¯„ä¼°ï¼š
1. æµåŠ¨æ€§é£é™©ç­‰çº§
2. å¸‚å€¼è§„æ¨¡é£é™©
3. ä¼°å€¼é£é™©
4. å¸‚åœºé£é™©
5. å…·ä½“é£é™©æ§åˆ¶å»ºè®®

è¯·æä¾›ä¸“ä¸šçš„é£é™©è¯„ä¼°ï¼ˆ120å­—ä»¥å†…ï¼‰ã€‚
"""
            try:
                analysis = get_real_llm_analysis(prompt, {'risk_data': data})
                return f"ã€LLMé£é™©è¯„ä¼°ã€‘{analysis}"
            except Exception as e:
                print(f"LLM risk analysis failed: {e}")
                pass
        
        # åŸºç¡€é£é™©åˆ†æ
        turnover = data.get('turnover', 5)
        market_cap = data.get('market_cap', 1000)
        price = data.get('current_price', 0)
        
        risk_level = 'ä¸­ç­‰'
        risk_factors = []
        
        if turnover > 10:
            risk_level = 'è¾ƒé«˜'
            risk_factors.append('é«˜æ¢æ‰‹ç‡æ˜¾ç¤ºæŠ•æœºæ€§å¼º')
        elif turnover < 2:
            risk_level = 'è¾ƒä½'
            risk_factors.append('ä½æ¢æ‰‹ç‡æµåŠ¨æ€§ä¸è¶³')
            
        if market_cap < 100:
            risk_factors.append('å°å¸‚å€¼è‚¡ç¥¨æ³¢åŠ¨æ€§å¤§')
        elif market_cap > 5000:
            risk_factors.append('å¤§å¸‚å€¼è‚¡ç¥¨ç›¸å¯¹ç¨³å®š')
            
        factors_text = 'ï¼Œ'.join(risk_factors) if risk_factors else 'é£é™©å› ç´ é€‚ä¸­'
        return f'ã€é£é™©è¯„ä¼°ã€‘æµåŠ¨æ€§é£é™©{risk_level}(æ¢æ‰‹ç‡:{turnover}%)ï¼Œå¸‚å€¼{market_cap}äº¿ã€‚{factors_text}'
    except Exception as e:
        return f'é£é™©åˆ†æå¼‚å¸¸: {str(e)}'

def analyze_quantitative(symbol, stock_data, technical_data, use_llm=False):
    """é‡åŒ–åˆ†æ - æ”¯æŒLLMæ·±åº¦åˆ†æ"""
    try:
        if use_llm:
            prompt = f"""
ä½œä¸ºé‡åŒ–åˆ†æå¸ˆï¼Œè¯·å¯¹è‚¡ç¥¨ {symbol} è¿›è¡Œé‡åŒ–å»ºæ¨¡åˆ†æï¼š

é‡åŒ–æ•°æ®ï¼š
è‚¡ç¥¨æ•°æ®: PE={stock_data.get('pe_ratio', 'æœªçŸ¥')}, PB={stock_data.get('pb_ratio', 'æœªçŸ¥')}, å¸‚å€¼={stock_data.get('market_cap', 'æœªçŸ¥')}äº¿
æŠ€æœ¯æ•°æ®: RSI={technical_data.get('RSI', 'æœªçŸ¥')}, MACD={technical_data.get('MACD', 'æœªçŸ¥')}, MA20={technical_data.get('MA20', 'æœªçŸ¥')}
ä»·æ ¼æ•°æ®: å½“å‰={stock_data.get('current_price', 'æœªçŸ¥')}å…ƒ, æ¢æ‰‹ç‡={stock_data.get('turnover', 'æœªçŸ¥')}%

è¯·è¿›è¡Œï¼š
1. å¤šå› å­æ¨¡å‹è¯„åˆ†
2. æŠ€æœ¯ä¿¡å·å¼ºåº¦è¯„ä¼°
3. é£é™©æ”¶ç›Šæ¯”è®¡ç®—
4. é‡åŒ–äº¤æ˜“ä¿¡å·
5. å…·ä½“ä»“ä½å»ºè®®

è¯·æä¾›é‡åŒ–åˆ†æç»“è®ºï¼ˆ150å­—ä»¥å†…ï¼‰ã€‚
"""
            try:
                analysis = get_real_llm_analysis(prompt, {'stock_data': stock_data, 'technical_data': technical_data})
                return f"ã€LLMé‡åŒ–åˆ†æã€‘{analysis}"
            except Exception as e:
                print(f"LLM quantitative analysis failed: {e}")
                pass
        
        # åŸºç¡€é‡åŒ–è¯„åˆ†
        score = 0
        factors = []
        
        # ä¼°å€¼å› å­
        pe = stock_data.get('pe_ratio', 20)
        if pe < 15:
            score += 1
            factors.append('ä¼°å€¼ä¼˜åŠ¿(ä½PE)')
        elif pe > 30:
            score -= 1
            factors.append('ä¼°å€¼åŠ£åŠ¿(é«˜PE)')
            
        # æŠ€æœ¯å› å­
        rsi = technical_data.get('RSI', 50)
        if 30 < rsi < 70:
            score += 0.5
            factors.append('æŠ€æœ¯é¢ä¸­æ€§')
        elif rsi < 30:
            score += 1
            factors.append('æŠ€æœ¯é¢è¶…å–')
        elif rsi > 70:
            score -= 0.5
            factors.append('æŠ€æœ¯é¢è¶…ä¹°')
            
        # æµåŠ¨æ€§å› å­
        turnover = stock_data.get('turnover', 5)
        if 3 < turnover < 15:
            score += 0.3
            factors.append('æµåŠ¨æ€§é€‚ä¸­')
            
        return f'ã€é‡åŒ–æ¨¡å‹ã€‘ç»¼åˆè¯„åˆ†:{score:.1f}åˆ†ï¼Œå…³é”®å› å­:{"ã€".join(factors) if factors else "æ— æ˜æ˜¾å› å­"}'
    except Exception as e:
        return f'é‡åŒ–åˆ†æå¼‚å¸¸: {str(e)}'

def synthesize_agent_decisions(symbol, agents_analysis, stock_data, news_data, technical_data):
    """ç»¼åˆå†³ç­–å¸ˆ - æ•´åˆæ‰€æœ‰æ™ºèƒ½ä½“åˆ†æç»“æœ"""
    try:
        prompt = f"""
ä½œä¸ºé¦–å¸­æŠ•èµ„ç­–ç•¥å¸ˆï¼Œè¯·ç»¼åˆä»¥ä¸‹å¤šä¸ªä¸“ä¸šåˆ†æå¸ˆçš„è§‚ç‚¹ï¼Œå¯¹è‚¡ç¥¨ {symbol} ({stock_data.get('name', 'æœªçŸ¥')}) åšå‡ºæœ€ç»ˆæŠ•èµ„å†³ç­–ï¼š

å„åˆ†æå¸ˆè§‚ç‚¹ï¼š
åŸºæœ¬é¢åˆ†æå¸ˆ: {agents_analysis.get('åŸºæœ¬é¢åˆ†æå¸ˆ', 'æ— ')}
æŠ€æœ¯åˆ†æå¸ˆ: {agents_analysis.get('æŠ€æœ¯åˆ†æå¸ˆ', 'æ— ')}
æƒ…æ„Ÿåˆ†æå¸ˆ: {agents_analysis.get('æƒ…æ„Ÿåˆ†æå¸ˆ', 'æ— ')}
é£é™©æ§åˆ¶å¸ˆ: {agents_analysis.get('é£é™©æ§åˆ¶å¸ˆ', 'æ— ')}
é‡åŒ–åˆ†æå¸ˆ: {agents_analysis.get('é‡åŒ–åˆ†æå¸ˆ', 'æ— ')}

ç»¼åˆæ•°æ®ï¼š
- å½“å‰ä»·æ ¼: {stock_data.get('current_price', 'æœªçŸ¥')}å…ƒ
- PE/PB: {stock_data.get('pe_ratio', 'æœªçŸ¥')}/{stock_data.get('pb_ratio', 'æœªçŸ¥')}
- RSI/MACD: {technical_data.get('RSI', 'æœªçŸ¥')}/{technical_data.get('MACD', 'æœªçŸ¥')}
- å¸‚åœºæƒ…æ„Ÿ: {news_data.get('sentiment_text', 'æœªçŸ¥')}

è¯·åˆ†æå„åˆ†æå¸ˆè§‚ç‚¹çš„ä¸€è‡´æ€§å’Œåˆ†æ­§ç‚¹ï¼Œç»™å‡ºï¼š
1. ç»¼åˆæŠ•èµ„è¯„çº§ï¼ˆä¹°å…¥/æŒæœ‰/å–å‡ºï¼‰
2. ç½®ä¿¡åº¦ï¼ˆ1-100%ï¼‰
3. ä¸»è¦æ”¯æ’‘ç†ç”±
4. æ ¸å¿ƒé£é™©ç‚¹
5. å…·ä½“æ‰§è¡Œå»ºè®®

è¯·æä¾›æœ€ç»ˆå†³ç­–ï¼ˆ200å­—ä»¥å†…ï¼‰ã€‚
"""
        
        try:
            analysis = get_real_llm_analysis(prompt, {
                'agents': agents_analysis,
                'stock_data': stock_data,
                'news_data': news_data,
                'technical_data': technical_data
            })
            return f"ã€ç»¼åˆå†³ç­–ã€‘{analysis}"
        except Exception as e:
            print(f"LLM synthesis failed: {e}")
            return "ã€ç»¼åˆå†³ç­–ã€‘ç³»ç»Ÿæ­£åœ¨æ•´åˆå¤šç»´åº¦åˆ†æç»“æœï¼Œå„åˆ†æå¸ˆè§‚ç‚¹å·²æ”¶é›†å®Œæ¯•ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†åˆ†ææŠ¥å‘Šã€‚"
    except Exception as e:
        return f'ç»¼åˆå†³ç­–åˆ†æå¼‚å¸¸: {str(e)}'

def generate_thinking_process(symbol, mode, agents_analysis):
    """ç”ŸæˆçœŸå®çš„æ€è€ƒè¿‡ç¨‹ - åæ˜ å®é™…APIè°ƒç”¨"""
    # ç›´æ¥æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼Œä¸ä¾èµ–configå¯¹è±¡
    flask_env = os.getenv('FLASK_ENV', 'development')
    is_render_deployment = os.getenv('RENDER') or os.getenv('RENDER_SERVICE_ID') or 'render' in os.getcwd().lower()
    use_real_data = REAL_DATA_AVAILABLE and (flask_env == 'production' or is_render_deployment)
    
    thinking_steps = [
        f'ğŸ” å¼€å§‹åˆ†æè‚¡ç¥¨ {symbol} - {get_stock_name(symbol)}',
        f'ğŸ“Š é€‰æ‹©åˆ†ææ¨¡å¼: {mode}',
        f'ğŸ”§ ç³»ç»Ÿç¯å¢ƒ: {flask_env} | Renderæ£€æµ‹: {"âœ…" if is_render_deployment else "âŒ"} | çœŸå®æ•°æ®: {"âœ…" if use_real_data else "âŒæ¨¡æ‹Ÿæ¨¡å¼"}',
        '',
        'ğŸŒ æ•°æ®è·å–é˜¶æ®µ:',
        f'â”œâ”€ {"ğŸ”„ Tushare/AKShareå®æ—¶æ•°æ®è·å–..." if use_real_data else "âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®"}',
        f'â”œâ”€ {"ğŸ”„ Tavilyæ–°é—»æœç´¢APIè°ƒç”¨..." if use_real_data else "âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿæ–°é—»æ•°æ®"}',
        f'â””â”€ {"âœ… æŠ€æœ¯æŒ‡æ ‡å®æ—¶è®¡ç®—å®Œæˆ" if use_real_data else "âœ… æŠ€æœ¯æŒ‡æ ‡æ¨¡æ‹Ÿè®¡ç®—å®Œæˆ"}',
        '',
        'ğŸ¤– å¤šæ™ºèƒ½ä½“åˆ†æé˜¶æ®µ:',
        f'â”œâ”€ åŸºæœ¬é¢åˆ†æå¸ˆ: {"ğŸ§  DashScope LLMæ·±åº¦åˆ†æä¸­..." if use_real_data else "ğŸ“Š è§„åˆ™åˆ†æå®Œæˆ"}',
        f'â”œâ”€ æŠ€æœ¯åˆ†æå¸ˆ: {"ğŸ§  LLMæŠ€æœ¯é¢æ·±åº¦è§£è¯»ä¸­..." if use_real_data else "ğŸ“ˆ æŒ‡æ ‡è§„åˆ™åˆ†æå®Œæˆ"}',  
        f'â”œâ”€ æƒ…æ„Ÿåˆ†æå¸ˆ: {"ğŸ§  LLMæƒ…æ„Ÿè¯­ä¹‰åˆ†æä¸­..." if use_real_data else "ğŸ“° æƒ…æ„Ÿè§„åˆ™åˆ†æå®Œæˆ"}',
        f'â”œâ”€ é£é™©æ§åˆ¶å¸ˆ: {"ğŸ§  LLMé£é™©è¯„ä¼°åˆ†æä¸­..." if use_real_data else "âš ï¸ é£é™©è§„åˆ™åˆ†æå®Œæˆ"}',
        f'â””â”€ é‡åŒ–åˆ†æå¸ˆ: {"ğŸ§  LLMé‡åŒ–å»ºæ¨¡åˆ†æä¸­..." if use_real_data else "ğŸ“Š é‡åŒ–è§„åˆ™åˆ†æå®Œæˆ"}',
        '',
        'ğŸ§  æ™ºèƒ½ä½“åå•†é˜¶æ®µ:',
        'â”œâ”€ æ”¶é›†å„åˆ†æå¸ˆçš„ä¸“ä¸šè§‚ç‚¹',
        'â”œâ”€ è¯†åˆ«åˆ†æç»“æœçš„ä¸€è‡´æ€§å’Œåˆ†æ­§ç‚¹',
        'â”œâ”€ è¯„ä¼°å„è§‚ç‚¹çš„æƒé‡å’Œå¯ä¿¡åº¦',
        f'â””â”€ {"ğŸ¤– ç»¼åˆå†³ç­–å¸ˆ LLMæ•´åˆåˆ†æ..." if use_real_data else "ğŸ“‹ åŸºç¡€è§„åˆ™æ•´åˆå®Œæˆ"}',
        '',
        'ğŸ“Š åˆ†æç»“æœæ•´åˆ:',
        f'â€¢ åŸºæœ¬é¢: {agents_analysis.get("åŸºæœ¬é¢åˆ†æå¸ˆ", "åˆ†æä¸­...")}',
        f'â€¢ æŠ€æœ¯é¢: {agents_analysis.get("æŠ€æœ¯åˆ†æå¸ˆ", "åˆ†æä¸­...")}', 
        f'â€¢ æƒ…æ„Ÿé¢: {agents_analysis.get("æƒ…æ„Ÿåˆ†æå¸ˆ", "åˆ†æä¸­...")}',
        f'â€¢ é£é™©é¢: {agents_analysis.get("é£é™©æ§åˆ¶å¸ˆ", "åˆ†æä¸­...")}',
        f'â€¢ é‡åŒ–é¢: {agents_analysis.get("é‡åŒ–åˆ†æå¸ˆ", "åˆ†æä¸­...")}',
    ]
    
    # å¦‚æœæœ‰ç»¼åˆå†³ç­–å¸ˆç»“æœï¼Œæ·»åŠ åˆ°æ€è€ƒè¿‡ç¨‹ä¸­
    if 'ç»¼åˆå†³ç­–å¸ˆ' in agents_analysis:
        thinking_steps.extend([
            '',
            'âš–ï¸ æœ€ç»ˆå†³ç­–é˜¶æ®µ:',
            f'â””â”€ {agents_analysis.get("ç»¼åˆå†³ç­–å¸ˆ", "å†³ç­–ç”Ÿæˆä¸­...")}'
        ])
    
    thinking_steps.extend([
        '',
        f'âœ… {"å¤šç»´åº¦æ™ºèƒ½åˆ†æå®Œæˆ" if use_real_data else "åŸºç¡€åˆ†æå®Œæˆ"}'
    ])
    
    return '\n'.join(thinking_steps)

def generate_final_recommendation(symbol, stock_data, news_data, technical_data, agents_analysis):
    """ç”Ÿæˆæœ€ç»ˆæ¨è"""
    try:
        # ç®€å•çš„å†³ç­–é€»è¾‘
        score = 0
        confidence = 0.7
        
        # åŸºäºå„ç§åˆ†æç»“æœè®¡ç®—åˆ†æ•°
        pe = stock_data.get('pe_ratio', 20)
        rsi = technical_data.get('RSI', 50)
        sentiment = news_data.get('sentiment_score', 0)
        
        # ä¼°å€¼è¯„åˆ†
        if pe < 15:
            score += 2
        elif pe > 30:
            score -= 2
            
        # æŠ€æœ¯è¯„åˆ†  
        if rsi < 30:
            score += 1
        elif rsi > 70:
            score -= 1
            
        # æƒ…æ„Ÿè¯„åˆ†
        score += sentiment * 2
        
        # ç”Ÿæˆæ¨è
        if score > 1:
            recommendation = 'BUY'
            confidence = min(0.9, confidence + score * 0.1)
        elif score < -1:
            recommendation = 'SELL'
            confidence = min(0.9, confidence + abs(score) * 0.1)
        else:
            recommendation = 'HOLD'
            
        return {
            'recommendation': recommendation,
            'confidence': round(confidence, 2),
            'score': score,
            'reasoning': f'ç»¼åˆè¯„åˆ†{score}åˆ†ï¼ŒåŸºäºPEä¼°å€¼ã€RSIæŠ€æœ¯æŒ‡æ ‡ã€å¸‚åœºæƒ…æ„Ÿç­‰å¤šç»´åº¦åˆ†æ'
        }
    except Exception as e:
        return {
            'recommendation': 'HOLD',
            'confidence': 0.5,
            'score': 0,
            'reasoning': f'åˆ†æè¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}'
        }

@app.route('/')
def home():
    """ä¸»é¡µ - è¿”å›ä¸­æ–‡ç•Œé¢"""
    if 'text/html' in request.headers.get('Accept', ''):
        return render_template('index.html')
    
    return jsonify({
        'status': 'æ™ºèƒ½äº¤æ˜“åŠ©æ‰‹',
        'version': '2.0.0',
        'timestamp': datetime.now().isoformat(),
        'message': 'å¤šç»´åº¦è‚¡ç¥¨åˆ†æç³»ç»Ÿæ­£åœ¨è¿è¡Œï¼',
        'features': [
            'å®æ—¶æ•°æ®è·å– (Tushare)',
            'å¤šLLMååŒåˆ†æ (DeepSeek + é˜¿é‡Œäº‘)',
            'æ–°é—»æƒ…æ„Ÿåˆ†æ (Tavily)',
            'æŠ€æœ¯æŒ‡æ ‡è®¡ç®—',
            'å¤šæ™ºèƒ½ä½“å†³ç­–'
        ]
    })

@app.route('/test')
def test_dashboard():
    """æµ‹è¯•é¢æ¿é¡µé¢"""
    return render_template('test_dashboard.html')

@app.route('/api/config/check')
def check_config():
    """æ£€æŸ¥é…ç½®çŠ¶æ€"""
    api_status = config.check_api_availability()
    return jsonify({
        'apis': api_status,
        'trading_config': config.get_trading_config(),
        'flask_env': config.flask_env,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/info')
def api_info():
    """APIä¿¡æ¯"""
    return jsonify({
        'status': 'æ™ºèƒ½äº¤æ˜“åŠ©æ‰‹',
        'version': '2.0.0',
        'timestamp': datetime.now().isoformat(),
        'message': 'å¤šç»´åº¦è‚¡ç¥¨åˆ†æç³»ç»Ÿæ­£åœ¨è¿è¡Œï¼',
        'data_sources': ['Tushare', 'Tavily', 'Technical Analysis'],
        'ai_models': ['DeepSeek', 'Alibaba Cloud', 'Multi-Agent System']
    })

@app.route('/health')
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'message': 'ç³»ç»Ÿè¿è¡Œæ­£å¸¸',
        'version': 'v2.1.0-real-agents',
        'deploy_time': datetime.now().isoformat(),
        'real_data_available': REAL_DATA_AVAILABLE,
        'services': {
            'web_server': 'running',
            'data_source': 'connected', 
            'ai_models': 'available',
            'cache': 'active'
        }
    })

@app.route('/features')
def feature_status():
    """åŠŸèƒ½çŠ¶æ€æ£€æŸ¥æ¥å£"""
    core_features = ['langchain', 'akshare', 'pandas', 'enhanced_agent']
    advanced_features = ['tushare', 'dashscope', 'tavily', 'real_time_data', 'news_search', 'enhanced_llm']
    
    core_available = all(AVAILABLE_FEATURES.get(f, False) for f in core_features)
    advanced_available = all(AVAILABLE_FEATURES.get(f, False) for f in advanced_features)
    
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat(),
        'available_features': AVAILABLE_FEATURES,
        'capabilities': {
            'basic_analysis': True,
            'real_time_data': AVAILABLE_FEATURES.get('tushare', False) or AVAILABLE_FEATURES.get('akshare', False),
            'ai_reasoning': AVAILABLE_FEATURES.get('enhanced_llm', False) or AVAILABLE_FEATURES.get('langchain', False),
            'enhanced_agents': AVAILABLE_FEATURES.get('enhanced_agent', False),
            'technical_analysis': AVAILABLE_FEATURES.get('pandas', False),
            'news_search': AVAILABLE_FEATURES.get('news_search', False),
            'multi_llm_support': AVAILABLE_FEATURES.get('dashscope', False)
        },
        'system_level': 'advanced' if advanced_available else ('core' if core_available else 'basic'),
        'recommendation': (
            'Full AI analysis with real-time data' if advanced_available else
            'Standard AI analysis' if core_available else
            'Basic analysis only'
        ),
        'missing_features': [f for f in advanced_features if not AVAILABLE_FEATURES.get(f, False)]
    })

@app.route('/debug')
def debug_status():
    """è°ƒè¯•çŠ¶æ€æ¥å£"""
    # ç›´æ¥ä»ç¯å¢ƒå˜é‡è·å–ï¼Œç¡®ä¿å‡†ç¡®æ€§
    flask_env = os.getenv('FLASK_ENV', 'development')
    config_env = getattr(config, 'flask_env', 'unknown') if config else 'no_config'
    
    return jsonify({
        'timestamp': datetime.now().isoformat(),
        'environment': {
            'flask_env_from_os': flask_env,
            'flask_env_from_config': config_env,
            'python_version': sys.version,
            'working_directory': os.getcwd()
        },
        'real_data_integration': {
            'available': REAL_DATA_AVAILABLE,
            'should_use_real_data': REAL_DATA_AVAILABLE and flask_env == 'production',
            'env_check_result': f"OS={flask_env}, CONFIG={config_env}"
        },
        'environment_variables': {
            'FLASK_ENV': os.getenv('FLASK_ENV', 'NOT_SET'),
            'TUSHARE_TOKEN': 'SET' if os.getenv('TUSHARE_TOKEN') else 'NOT_SET',
            'DASHSCOPE_API_KEY': 'SET' if os.getenv('DASHSCOPE_API_KEY') else 'NOT_SET',
            'TAVILY_API_KEY': 'SET' if os.getenv('TAVILY_API_KEY') else 'NOT_SET'
        },
        'config_object': {
            'type': str(type(config)),
            'flask_env': getattr(config, 'flask_env', 'NOT_AVAILABLE'),
            'tushare_token': 'SET' if getattr(config, 'tushare_token', None) else 'NOT_SET',
            'dashscope_api_key': 'SET' if getattr(config, 'dashscope_api_key', None) else 'NOT_SET'
        },
        'feature_detection': AVAILABLE_FEATURES,
        'system_diagnosis': {
            'real_data_ready': REAL_DATA_AVAILABLE and flask_env == 'production',
            'reason': (
                'Real data integration ready' if REAL_DATA_AVAILABLE and flask_env == 'production' 
                else f'REAL_DATA_AVAILABLE={REAL_DATA_AVAILABLE}, flask_env_os={flask_env}, flask_env_config={config_env}'
            ),
            'blocking_factors': [
                f"REAL_DATA_AVAILABLE: {REAL_DATA_AVAILABLE}",
                f"FLASK_ENV from OS: {flask_env}",
                f"FLASK_ENV from CONFIG: {config_env}",
                f"Environment check result: {flask_env == 'production'}"
            ]
        }
    })

@app.route('/test-real-data/<symbol>')
def test_real_data(symbol):
    """æµ‹è¯•å®æ—¶æ•°æ®è·å–"""
    if not AVAILABLE_FEATURES.get('real_time_data', False):
        return jsonify({
            'error': 'Real-time data service not available',
            'available_features': AVAILABLE_FEATURES
        }), 503
    
    try:
        from real_time_data_service import get_data_service
        data_service = get_data_service()
        
        # ç”±äºæ˜¯åŒæ­¥ç«¯ç‚¹ï¼Œä½¿ç”¨asyncio.run()
        import asyncio
        quote_data = asyncio.run(data_service.get_real_time_quote(symbol))
        
        return jsonify({
            'status': 'success',
            'symbol': symbol,
            'data': quote_data,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'error': f'Real-time data test failed: {str(e)}',
            'symbol': symbol
        }), 500

@app.route('/test-news/<symbol>')
def test_news(symbol):
    """æµ‹è¯•æ–°é—»æœç´¢"""
    if not AVAILABLE_FEATURES.get('news_search', False):
        return jsonify({
            'error': 'News search service not available',
            'available_features': AVAILABLE_FEATURES
        }), 503
    
    try:
        from news_search_service import get_news_service
        news_service = get_news_service()
        
        # ç”±äºæ˜¯åŒæ­¥ç«¯ç‚¹ï¼Œä½¿ç”¨asyncio.run()
        import asyncio
        news_data = asyncio.run(news_service.search_stock_news(symbol, limit=5))
        
        return jsonify({
            'status': 'success',
            'symbol': symbol,
            'news_count': len(news_data),
            'news': news_data,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'error': f'News search test failed: {str(e)}',
            'symbol': symbol
        }), 500

@app.route('/test-llm')
def test_llm():
    """æµ‹è¯•LLMæœåŠ¡"""
    if not AVAILABLE_FEATURES.get('enhanced_llm', False):
        return jsonify({
            'error': 'Enhanced LLM service not available',
            'available_features': AVAILABLE_FEATURES
        }), 503
    
    try:
        from enhanced_llm_service import get_llm_service
        llm_service = get_llm_service()
        
        # æµ‹è¯•åŸºç¡€è°ƒç”¨
        import asyncio
        test_prompt = "è¯·ç®€è¦åˆ†æå½“å‰Aè‚¡å¸‚åœºçš„æ•´ä½“è¶‹åŠ¿ï¼Œä¸è¶…è¿‡100å­—ã€‚"
        response = asyncio.run(llm_service.ainvoke(test_prompt, model='qwen-turbo'))
        
        return jsonify({
            'status': 'success',
            'prompt': test_prompt,
            'response': response,
            'model': 'qwen-turbo',
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'error': f'LLM test failed: {str(e)}',
            'prompt': test_prompt
        }), 500

@app.route('/analyze', methods=['POST'])
def analyze_stock():
    """è‚¡ç¥¨åˆ†æä¸»æ¥å£"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æä¾›åˆ†æå‚æ•°'}), 400
            
        symbol = data.get('symbol', '').upper()
        date = data.get('date', datetime.now().strftime('%Y-%m-%d'))
        mode = data.get('mode', 'comprehensive')
        detailed = data.get('detailed', True)
        
        if not symbol:
            return jsonify({'error': 'è¯·æä¾›è‚¡ç¥¨ä»£ç '}), 400
            
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f'{symbol}_{date}_{mode}'
        if cache_key in analysis_cache:
            cached_result = analysis_cache[cache_key]
            cached_result['from_cache'] = True
            return jsonify(cached_result)
        
        # æ‰§è¡Œåˆ†æ
        analysis_start = time.time()
        
        # 1. è·å–è‚¡ç¥¨æ•°æ®
        stock_data = get_stock_data(symbol)
        if 'error' in stock_data:
            return jsonify(stock_data), 500
            
        # 2. è·å–æ–°é—»åˆ†æ
        news_data = get_news_analysis(symbol)
        
        # 3. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        technical_data = get_technical_indicators(symbol)
        
        # 4. å¤šæ™ºèƒ½ä½“åˆ†æ
        agents_analysis = multi_agent_analysis(symbol, stock_data, news_data, technical_data)
        
        # 5. ç”Ÿæˆæ€è€ƒè¿‡ç¨‹
        thinking_process = generate_thinking_process(symbol, mode, agents_analysis)
        
        # 6. ç”Ÿæˆæœ€ç»ˆæ¨è
        recommendation = generate_final_recommendation(symbol, stock_data, news_data, technical_data, agents_analysis)
        
        # æ„å»ºå®Œæ•´ç»“æœ
        result = {
            'symbol': symbol,
            'name': stock_data.get('name', ''),
            'date': date,
            'mode': mode,
            'analysis': recommendation,
            'thinking_process': thinking_process,
            'multi_agent_analysis': agents_analysis,
            'news_analysis': news_data,
            'technical_indicators': technical_data,
            'stock_data': stock_data,
            'processing_time': round((time.time() - analysis_start) * 1000, 2),
            'timestamp': datetime.now().isoformat(),
            'from_cache': False
        }
        
        # ç¼“å­˜ç»“æœ (5åˆ†é’Ÿ)
        analysis_cache[cache_key] = result
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'error': f'åˆ†æå¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc() if app.debug else None
        }), 500

# å®šæœŸæ¸…ç†ç¼“å­˜
def cleanup_cache():
    """æ¸…ç†è¿‡æœŸç¼“å­˜"""
    while True:
        time.sleep(300)  # 5åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
        if len(analysis_cache) > 100:  # é™åˆ¶ç¼“å­˜å¤§å°
            # æ¸…ç†ä¸€åŠçš„æ—§ç¼“å­˜
            keys_to_remove = list(analysis_cache.keys())[:len(analysis_cache)//2]
            for key in keys_to_remove:
                analysis_cache.pop(key, None)

# å¯åŠ¨ç¼“å­˜æ¸…ç†çº¿ç¨‹
cleanup_thread = threading.Thread(target=cleanup_cache, daemon=True)
cleanup_thread.start()

if __name__ == '__main__':
    # ç¯å¢ƒä¿¡æ¯æ‰“å°
    print("=" * 60)
    print("ğŸš€ Trading Agent å¯åŠ¨ä¸­...")
    print(f"ğŸ Pythonç‰ˆæœ¬: {sys.version}")
    print(f"ğŸ“ å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ”§ Flaskç‰ˆæœ¬: {getattr(__import__('flask'), '__version__', 'unknown')}")
    
    # ç¯å¢ƒå˜é‡æ£€æŸ¥
    env_vars = {
        'PORT': os.getenv('PORT', '5000'),
        'FLASK_ENV': os.getenv('FLASK_ENV', 'development'),
        'TUSHARE_TOKEN': 'å·²é…ç½®' if os.getenv('TUSHARE_TOKEN') else 'æœªé…ç½®',
        'DASHSCOPE_API_KEY': 'å·²é…ç½®' if os.getenv('DASHSCOPE_API_KEY') else 'æœªé…ç½®',
        'TAVILY_API_KEY': 'å·²é…ç½®' if os.getenv('TAVILY_API_KEY') else 'æœªé…ç½®'
    }
    
    print("\nğŸ”‘ ç¯å¢ƒå˜é‡çŠ¶æ€:")
    for key, value in env_vars.items():
        print(f"  {key}: {value}")
    
    # åŠŸèƒ½æ£€æŸ¥
    print(f"\nâš¡ å¯ç”¨åŠŸèƒ½: {AVAILABLE_FEATURES}")
    
    port = int(os.environ.get('PORT', 5000))
    host = '0.0.0.0'
    
    print(f"\nğŸŒ å¯åŠ¨WebæœåŠ¡ {host}:{port}")
    print("ğŸ“Š æ•°æ®æº: Tushare + AKShare + Tavily")
    print("ğŸ¤– AIå¼•æ“: DashScope + Multi-Agent System")
    print("=" * 60)
    
    try:
        app.run(host=host, port=port, debug=False, threaded=True)
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
