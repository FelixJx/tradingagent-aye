#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆtushareæµ‹è¯• - éªŒè¯æ•°æ®è´¨é‡å’ŒåŸºç¡€å› å­
"""

import tushare as ts
import pandas as pd
import numpy as np
from datetime import datetime

def test_tushare_data_quality():
    """
    æµ‹è¯•tushareæ•°æ®è´¨é‡å’Œè®¡ç®—åŸºç¡€å› å­
    """
    print("ğŸš€ å¯åŠ¨tushareæ•°æ®è´¨é‡æµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–tushare
    token = 'b34d8920b99b43d48df7e792a4708a29f868feeee30d9c84b54bf065'
    ts.set_token(token)
    pro = ts.pro_api()
    
    # æµ‹è¯•è‚¡ç¥¨
    test_stocks = ['000001.SZ', '000002.SZ', '600036.SH']
    
    for i, stock_code in enumerate(test_stocks, 1):
        print(f"\nğŸ“Š [{i}/{len(test_stocks)}] æµ‹è¯• {stock_code}")
        print("-" * 40)
        
        try:
            # è·å–3ä¸ªæœˆæ•°æ®
            print("ğŸ“¡ è·å–ä»·æ ¼æ•°æ®...")
            df = pro.daily(ts_code=stock_code, 
                          start_date='20250501', 
                          end_date='20250731')
            
            if df.empty:
                print("âŒ æ— ä»·æ ¼æ•°æ®")
                continue
            
            df['trade_date'] = pd.to_datetime(df['trade_date'])
            df = df.sort_values('trade_date').reset_index(drop=True)
            
            print(f"âœ… è·å¾— {len(df)} æ¡ä»·æ ¼è®°å½•")
            print(f"   æ—¶é—´è·¨åº¦: {df['trade_date'].min().date()} åˆ° {df['trade_date'].max().date()}")
            print(f"   ä»·æ ¼èŒƒå›´: {df['close'].min():.2f} - {df['close'].max():.2f}")
            
            # è·å–åŸºæœ¬é¢æ•°æ®
            print("ğŸ’¼ è·å–åŸºæœ¬é¢æ•°æ®...")
            latest_date = df.iloc[0]['trade_date'].strftime('%Y%m%d')
            
            try:
                basic_data = pro.daily_basic(
                    ts_code=stock_code, 
                    trade_date=latest_date,
                    fields='ts_code,pe,pb,total_mv,turnover_rate'
                )
                
                if not basic_data.empty:
                    row = basic_data.iloc[0]
                    print(f"âœ… åŸºæœ¬é¢æ•°æ®è·å–æˆåŠŸ")
                    print(f"   PE: {row['pe'] if pd.notna(row['pe']) else 'N/A'}")
                    print(f"   PB: {row['pb'] if pd.notna(row['pb']) else 'N/A'}")
                    print(f"   å¸‚å€¼: {row['total_mv'] if pd.notna(row['total_mv']) else 'N/A'}ä¸‡å…ƒ")
                else:
                    print("âš ï¸ åŸºæœ¬é¢æ•°æ®ä¸ºç©º")
                    
            except Exception as e:
                print(f"âš ï¸ åŸºæœ¬é¢æ•°æ®è·å–å¤±è´¥: {str(e)[:50]}")
            
            # è®¡ç®—åŸºç¡€å› å­
            print("âš™ï¸ è®¡ç®—åŸºç¡€å› å­...")
            
            # 1. æ”¶ç›Šç‡
            returns = df['close'].pct_change()
            
            # 2. åŠ¨é‡å› å­
            momentum_5d = (df['close'] - df['close'].shift(5)) / df['close'].shift(5)
            momentum_20d = (df['close'] - df['close'].shift(20)) / df['close'].shift(20)
            
            # 3. æ³¢åŠ¨ç‡å› å­
            volatility_5d = returns.rolling(5).std()
            volatility_20d = returns.rolling(20).std()
            
            # 4. ç§»åŠ¨å¹³å‡
            ma_5 = df['close'].rolling(5).mean()
            ma_20 = df['close'].rolling(20).mean()
            ma_ratio_5 = df['close'] / ma_5
            ma_ratio_20 = df['close'] / ma_20
            
            # 5. RSI
            delta = df['close'].diff()
            gain = delta.where(delta > 0, 0).rolling(14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
            rs = gain / loss
            rsi_14 = 100 - (100 / (1 + rs))
            
            # 6. æˆäº¤é‡æ¯”ç‡
            vol_ma_5 = df['vol'].rolling(5).mean()
            vol_ma_20 = df['vol'].rolling(20).mean()
            vol_ratio_5 = df['vol'] / vol_ma_5
            vol_ratio_20 = df['vol'] / vol_ma_20
            
            # ç»Ÿè®¡å› å­æœ‰æ•ˆå€¼
            factors = {
                'momentum_5d': momentum_5d,
                'momentum_20d': momentum_20d,
                'volatility_5d': volatility_5d,
                'volatility_20d': volatility_20d,
                'ma_ratio_5': ma_ratio_5,
                'ma_ratio_20': ma_ratio_20,
                'rsi_14': rsi_14,
                'vol_ratio_5': vol_ratio_5,
                'vol_ratio_20': vol_ratio_20
            }
            
            print("ğŸ“ˆ å› å­ç»Ÿè®¡:")
            valid_factor_count = 0
            
            for factor_name, factor_values in factors.items():
                valid_values = factor_values.dropna()
                if len(valid_values) > 0:
                    valid_factor_count += 1
                    mean_val = valid_values.mean()
                    std_val = valid_values.std()
                    print(f"   {factor_name:<15}: {len(valid_values):2d}ä¸ªæœ‰æ•ˆå€¼, å‡å€¼{mean_val:7.4f}, æ ‡å‡†å·®{std_val:7.4f}")
            
            print(f"âœ… æˆåŠŸè®¡ç®— {valid_factor_count} ä¸ªæœ‰æ•ˆå› å­")
            
            # ç®€å•çš„é¢„æµ‹èƒ½åŠ›æµ‹è¯•
            print("ğŸ¯ ç®€å•é¢„æµ‹èƒ½åŠ›æµ‹è¯•...")
            
            # è®¡ç®—5æ—¥æœªæ¥æ”¶ç›Š
            future_return_5d = df['close'].shift(-5) / df['close'] - 1
            
            # æµ‹è¯•å‡ ä¸ªå…³é”®å› å­ä¸æœªæ¥æ”¶ç›Šçš„ç›¸å…³æ€§
            correlation_results = {}
            
            test_factors = ['momentum_5d', 'volatility_20d', 'rsi_14', 'vol_ratio_20']
            
            for factor_name in test_factors:
                if factor_name in factors:
                    factor_values = factors[factor_name]
                    
                    # å¯¹é½æ•°æ®
                    aligned_data = pd.DataFrame({
                        'factor': factor_values,
                        'future_return': future_return_5d
                    }).dropna()
                    
                    if len(aligned_data) >= 10:
                        corr = aligned_data['factor'].corr(aligned_data['future_return'])
                        if not pd.isna(corr):
                            correlation_results[factor_name] = {
                                'correlation': corr,
                                'sample_size': len(aligned_data)
                            }
            
            if correlation_results:
                print("ğŸ“Š å› å­é¢„æµ‹èƒ½åŠ› (ä¸5æ—¥æœªæ¥æ”¶ç›Šç›¸å…³æ€§):")
                sorted_corr = sorted(correlation_results.items(), 
                                   key=lambda x: abs(x[1]['correlation']), reverse=True)
                
                for factor_name, metrics in sorted_corr:
                    corr = metrics['correlation']
                    size = metrics['sample_size']
                    print(f"   {factor_name:<15}: ç›¸å…³æ€§{corr:7.4f} (æ ·æœ¬{size:2d}ä¸ª)")
                
                # æ‰¾å‡ºæœ€ä½³å› å­
                best_factor = sorted_corr[0]
                print(f"ğŸ† æœ€ä½³å› å­: {best_factor[0]} (ç›¸å…³æ€§ {best_factor[1]['correlation']:.4f})")
            else:
                print("âš ï¸ æ— æ³•è®¡ç®—é¢„æµ‹èƒ½åŠ›")
                
        except Exception as e:
            print(f"âŒ {stock_code} åˆ†æå¤±è´¥: {e}")
            
        print("-" * 40)
    
    print("\nğŸ‰ tushareæ•°æ®è´¨é‡æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ“‹ æ€»ç»“:")
    print("âœ“ tushareè¿æ¥ç¨³å®š")
    print("âœ“ å¯ä»¥è·å–å®Œæ•´çš„OHLCVæ•°æ®")
    print("âœ“ å¯ä»¥è·å–åŸºæœ¬é¢æ•°æ®(PE/PB/å¸‚å€¼)")
    print("âœ“ èƒ½å¤Ÿè®¡ç®—å„ç±»æŠ€æœ¯å› å­")
    print("âœ“ å› å­ä¸æœªæ¥æ”¶ç›Šæœ‰ä¸€å®šç›¸å…³æ€§")
    print("\nğŸ’¡ å»ºè®®: tushareæ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥ç”¨äºç”Ÿäº§ç¯å¢ƒçš„å› å­åˆ†æ")

if __name__ == "__main__":
    test_tushare_data_quality()