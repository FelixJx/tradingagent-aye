# -*- coding: utf-8 -*-
"""
åŸºäºçœŸå®æ•°æ®çš„å¢å¼ºå› å­ç³»ç»Ÿ
æ”¯æŒç¦»çº¿CSVæ•°æ®å’Œç½‘ç»œæ•°æ®ä¸¤ç§æ¨¡å¼
"""

import pandas as pd
import numpy as np
import os
import sqlite3
import tushare as ts
from typing import Dict, List, Optional
import warnings
warnings.filterwarnings('ignore')

try:
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import StandardScaler
    ML_AVAILABLE = True
    print("âœ… æœºå™¨å­¦ä¹ å·¥å…·å¯ç”¨")
except ImportError:
    ML_AVAILABLE = False
    print("âš ï¸ æœºå™¨å­¦ä¹ å·¥å…·ä¸å¯ç”¨")

class RealDataFactorSystem:
    """
    çœŸå®æ•°æ®å¢å¼ºå› å­ç³»ç»Ÿ
    ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ•°æ®ï¼Œç½‘ç»œä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§
    """
    
    def __init__(self, tushare_token: str = None, data_dir: str = './data'):
        """
        åˆå§‹åŒ–ç³»ç»Ÿ
        
        Args:
            tushare_token: tushare tokenï¼ˆå¯é€‰ï¼‰
            data_dir: æœ¬åœ°æ•°æ®ç›®å½•
        """
        self.data_dir = data_dir
        self.tushare_available = False
        
        # å°è¯•åˆå§‹åŒ–tushare
        if tushare_token:
            try:
                ts.set_token(tushare_token)
                self.pro = ts.pro_api()
                # æµ‹è¯•è¿æ¥
                test_df = self.pro.trade_cal(exchange='', start_date='20240101', end_date='20240102')
                if not test_df.empty:
                    self.tushare_available = True
                    print("âœ… tushareè¿æ¥æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ tushareè¿æ¥å¤±è´¥: {e}")
                self.tushare_available = False
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(data_dir, exist_ok=True)
        
        print(f"æ•°æ®æ¨¡å¼: {'åœ¨çº¿+ç¼“å­˜' if self.tushare_available else 'ä»…æœ¬åœ°ç¼“å­˜'}")
    
    def _load_from_qlib_database(self, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        ä»qlibæ•°æ®åº“åŠ è½½çœŸå®è‚¡ç¥¨æ•°æ®
        """
        qlib_db_path = '/Users/jx/Downloads/qlib-main/databases/real_tushare_factor_analysis.db'
        
        if not os.path.exists(qlib_db_path):
            return pd.DataFrame()
        
        try:
            conn = sqlite3.connect(qlib_db_path)
            
            # æ„å»ºæŸ¥è¯¢SQL
            query = """
            SELECT ts_code, trade_date, open, high, low, close, vol, amount, pct_chg,
                   volatility_5d, volatility_10d, volatility_20d, 
                   volume_ratio_5d, volume_ratio_10d, volume_ratio_20d,
                   rsi_14, ma_distance_5d, ma_distance_10d
            FROM factor_data 
            WHERE ts_code = ? 
            AND trade_date >= ? 
            AND trade_date <= ?
            ORDER BY trade_date
            """
            
            df = pd.read_sql_query(query, conn, params=[stock_code, start_date, end_date])
            conn.close()
            
            if not df.empty:
                df['trade_date'] = pd.to_datetime(df['trade_date'])
                # æ·»åŠ turnover_rateåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                if 'turnover_rate' not in df.columns:
                    df['turnover_rate'] = df['vol'] / 1e8  # ç®€åŒ–è®¡ç®—æ¢æ‰‹ç‡
            
            return df
            
        except Exception as e:
            print(f"ä»qlibæ•°æ®åº“åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_stock_data(self, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨æ•°æ®ï¼ˆä¼˜å…ˆæœ¬åœ°qllibæ•°æ®åº“ï¼Œç„¶åç½‘ç»œï¼Œæœ€åé™çº§åˆ°ç¼“å­˜ï¼‰
        """
        cache_file = os.path.join(self.data_dir, f"{stock_code}_{start_date}_{end_date}.csv")
        
        # 1. ä¼˜å…ˆä»qlibæ•°æ®åº“è·å–çœŸå®æ•°æ®
        qlib_data = self._load_from_qlib_database(stock_code, start_date, end_date)
        if not qlib_data.empty:
            print(f"âœ… ä»qlibæ•°æ®åº“è·å–åˆ° {len(qlib_data)} æ¡çœŸå®æ•°æ®è®°å½•")
            # ç¼“å­˜åˆ°æœ¬åœ°
            qlib_data.to_csv(cache_file, index=False)
            return qlib_data
        
        # 2. å°è¯•ä»ç½‘ç»œè·å–æœ€æ–°æ•°æ®
        if self.tushare_available:
            try:
                print(f"æ­£åœ¨ä»tushareè·å– {stock_code} æ•°æ®...")
                df = self.pro.daily(ts_code=stock_code, start_date=start_date, end_date=end_date)
                if not df.empty:
                    df['trade_date'] = pd.to_datetime(df['trade_date'])
                    df = df.sort_values('trade_date').reset_index(drop=True)
                    
                    # ç¼“å­˜åˆ°æœ¬åœ°
                    df.to_csv(cache_file, index=False)
                    print(f"âœ… è·å–åˆ° {len(df)} æ¡è®°å½•ï¼Œå·²ç¼“å­˜")
                    return df
            except Exception as e:
                print(f"âš ï¸ ç½‘ç»œè·å–å¤±è´¥ï¼Œå°è¯•æœ¬åœ°ç¼“å­˜: {e}")
        
        # 3. å°è¯•ä»æœ¬åœ°ç¼“å­˜åŠ è½½
        if os.path.exists(cache_file):
            try:
                df = pd.read_csv(cache_file)
                df['trade_date'] = pd.to_datetime(df['trade_date'])
                print(f"âœ… ä»ç¼“å­˜åŠ è½½ {len(df)} æ¡è®°å½•")
                return df
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        
        # 4. ä»é¡¹ç›®ä¸­ç°æœ‰æ•°æ®æ–‡ä»¶æŸ¥æ‰¾
        existing_files = [
            '000001.SZ_enhanced_factors.csv',  # ä¹‹å‰ç”Ÿæˆçš„æ–‡ä»¶
            f'{stock_code}_data.csv',
            f'{stock_code}.csv'
        ]
        
        for filename in existing_files:
            file_path = os.path.join('/Applications/tradingagent', filename)
            if os.path.exists(file_path):
                try:
                    df = pd.read_csv(file_path)
                    if 'trade_date' in df.columns:
                        df['trade_date'] = pd.to_datetime(df['trade_date'])
                        print(f"âœ… ä»é¡¹ç›®æ–‡ä»¶åŠ è½½: {filename}")
                        return df
                except:
                    continue
        
        # 5. ç”ŸæˆåŸºäºçœŸå®æ¨¡å¼çš„æ•°æ®ï¼ˆåŸºäºå†å²çœŸå®æ•°æ®ç‰¹å¾ï¼‰
        print(f"âš ï¸ æœªæ‰¾åˆ° {stock_code} æ•°æ®ï¼Œç”ŸæˆåŸºäºçœŸå®ç‰¹å¾çš„æ•°æ®")
        return self.generate_realistic_data(stock_code, start_date, end_date)
    
    def generate_realistic_data(self, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        ç”ŸæˆåŸºäºçœŸå®å¸‚åœºç‰¹å¾çš„æ•°æ®
        (åŸºäºAè‚¡å¸‚åœºçš„çœŸå®ç»Ÿè®¡ç‰¹å¾)
        """
        dates = pd.date_range(start_date, end_date, freq='D')
        dates = dates[dates.weekday < 5]  # å·¥ä½œæ—¥
        
        # åŸºäºAè‚¡çœŸå®ç‰¹å¾çš„å‚æ•°
        if stock_code.endswith('.SZ') or stock_code.endswith('.SH'):
            # Aè‚¡ç‰¹å¾å‚æ•°
            daily_return_mean = 0.0003  # å¹´åŒ–çº¦7.5%
            daily_return_std = 0.025    # å¹´åŒ–çº¦40%æ³¢åŠ¨ç‡
            volume_mean = 15.0          # log(æˆäº¤é‡)å‡å€¼
            volume_std = 0.8            # log(æˆäº¤é‡)æ ‡å‡†å·®
            base_price = 10.0 if stock_code.startswith('000001') else 20.0
        else:
            # å…¶ä»–å¸‚åœºé»˜è®¤å‚æ•°
            daily_return_mean = 0.0005
            daily_return_std = 0.02
            volume_mean = 16.0
            volume_std = 0.6
            base_price = 50.0
        
        np.random.seed(hash(stock_code) % 2**32)  # åŸºäºè‚¡ç¥¨ä»£ç çš„å›ºå®šç§å­
        
        # ç”Ÿæˆæ”¶ç›Šç‡åºåˆ—ï¼ˆåŒ…å«è¶‹åŠ¿å’Œå‡å€¼å›å½’ï¼‰
        returns = []
        trend = 0
        for i in range(len(dates)):
            # è¶‹åŠ¿æˆåˆ†
            trend += np.random.normal(0, 0.001)
            trend *= 0.99  # å‡å€¼å›å½’
            
            # éšæœºæˆåˆ†
            random_return = np.random.normal(daily_return_mean, daily_return_std)
            
            # æ³¢åŠ¨ç‡èšé›†æ•ˆåº”
            if i > 0 and abs(returns[-1]) > daily_return_std * 1.5:
                random_return *= 1.5  # é«˜æ³¢åŠ¨åç»§ç»­é«˜æ³¢åŠ¨
            
            total_return = trend + random_return
            returns.append(total_return)
        
        # ç”Ÿæˆä»·æ ¼åºåˆ—
        prices = [base_price]
        for ret in returns[1:]:
            prices.append(prices[-1] * (1 + ret))
        
        # ç”ŸæˆOHLC
        df_data = []
        for i, (date, price, ret) in enumerate(zip(dates, prices, returns)):
            # æ—¥å†…æ³¢åŠ¨
            intraday_range = abs(ret) * 2 + np.random.uniform(0.005, 0.02)
            
            open_price = price / (1 + ret) if i > 0 else price
            close_price = price
            
            high_price = max(open_price, close_price) * (1 + intraday_range * np.random.uniform(0.3, 1))
            low_price = min(open_price, close_price) * (1 - intraday_range * np.random.uniform(0.3, 1))
            
            # æˆäº¤é‡ï¼ˆä¸æ³¢åŠ¨ç‡æ­£ç›¸å…³ï¼‰
            volume_factor = 1 + abs(ret) * 10  # å¤§å¹…æ³¢åŠ¨æ—¶æ”¾é‡
            volume = np.random.lognormal(volume_mean, volume_std) * volume_factor
            
            df_data.append({
                'trade_date': date,
                'open': round(open_price, 2),
                'high': round(high_price, 2),
                'low': round(low_price, 2),
                'close': round(close_price, 2),
                'vol': int(volume),
                'amount': volume * close_price,
                'pct_chg': round(ret * 100, 2),
                'turnover_rate': round(np.random.uniform(0.5, 8.0), 2)
            })
        
        df = pd.DataFrame(df_data)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        cache_file = os.path.join(self.data_dir, f"{stock_code}_realistic_{start_date}_{end_date}.csv")
        df.to_csv(cache_file, index=False)
        
        print(f"âœ… ç”ŸæˆåŸºäºçœŸå®ç‰¹å¾çš„æ•°æ®: {len(df)} æ¡è®°å½•")
        return df
    
    def calculate_enhanced_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—å¢å¼ºç‰ˆå› å­ï¼ˆåŸºäºçœŸå®æ•°æ®ï¼‰
        """
        print("å¼€å§‹è®¡ç®—å¢å¼ºç‰ˆå› å­...")
        
        # ç¡®ä¿æ•°æ®è´¨é‡
        df = df.dropna().reset_index(drop=True)
        if len(df) < 60:
            print("âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—å®Œæ•´å› å­")
            return pd.DataFrame()
        
        factors = {}
        
        # Layer 1: åŸºç¡€æŠ€æœ¯å› å­
        print("  Layer 1: åŸºç¡€æŠ€æœ¯å› å­...")
        factors.update(self._calculate_basic_technical_factors(df))
        
        # Layer 2: é«˜çº§æŠ€æœ¯å› å­  
        print("  Layer 2: é«˜çº§æŠ€æœ¯å› å­...")
        factors.update(self._calculate_advanced_technical_factors(df))
        
        # Layer 3: å¸‚åœºå¾®è§‚ç»“æ„å› å­
        print("  Layer 3: å¸‚åœºå¾®è§‚ç»“æ„å› å­...")
        factors.update(self._calculate_microstructure_factors(df))
        
        # Layer 4: é‡ä»·å…³ç³»å› å­
        print("  Layer 4: é‡ä»·å…³ç³»å› å­...")
        factors.update(self._calculate_volume_price_factors(df))
        
        # æ„å»ºå› å­DataFrame
        factor_df = pd.DataFrame(factors, index=df.index)
        factor_df['trade_date'] = df['trade_date']
        factor_df['close'] = df['close']
        
        # è®¡ç®—æœªæ¥æ”¶ç›Šç‡ä½œä¸ºæ ‡ç­¾
        for period in [1, 5, 10, 20]:
            factor_df[f'future_return_{period}d'] = df['close'].shift(-period) / df['close'] - 1
        
        print(f"âœ… å®Œæˆå› å­è®¡ç®—: {len(factors)} ä¸ªå› å­")
        return factor_df
    
    def _calculate_basic_technical_factors(self, df: pd.DataFrame) -> Dict:
        """åŸºç¡€æŠ€æœ¯å› å­"""
        factors = {}
        
        # ä»·æ ¼åŠ¨é‡å› å­
        for period in [1, 3, 5, 10, 20, 40, 60]:
            factors[f'momentum_{period}'] = (df['close'] - df['close'].shift(period)) / df['close'].shift(period)
            factors[f'return_{period}'] = df['close'].pct_change(period)
        
        # ç§»åŠ¨å¹³å‡å› å­
        for period in [5, 10, 20, 30, 60]:
            factors[f'ma_{period}'] = df['close'].rolling(period).mean()
            factors[f'ma_ratio_{period}'] = df['close'] / factors[f'ma_{period}']
            factors[f'ma_distance_{period}'] = (df['close'] - factors[f'ma_{period}']) / factors[f'ma_{period}']
        
        # æ³¢åŠ¨ç‡å› å­
        returns = df['close'].pct_change()
        for period in [5, 10, 20, 60]:
            factors[f'volatility_{period}'] = returns.rolling(period).std()
            factors[f'volatility_ratio_{period}'] = factors[f'volatility_{period}'] / returns.rolling(60).std()
        
        # ä»·æ ¼ä½ç½®å› å­
        for period in [10, 20, 60, 120]:
            high_max = df['high'].rolling(period).max()
            low_min = df['low'].rolling(period).min()
            factors[f'price_position_{period}'] = (df['close'] - low_min) / (high_max - low_min)
            factors[f'from_high_{period}'] = (high_max - df['close']) / high_max
            factors[f'from_low_{period}'] = (df['close'] - low_min) / df['close']
        
        return factors
    
    def _calculate_advanced_technical_factors(self, df: pd.DataFrame) -> Dict:
        """é«˜çº§æŠ€æœ¯å› å­"""
        factors = {}
        
        # MACDç³»åˆ—
        exp12 = df['close'].ewm(span=12).mean()
        exp26 = df['close'].ewm(span=26).mean()
        macd = exp12 - exp26
        macd_signal = macd.ewm(span=9).mean()
        factors['macd'] = macd
        factors['macd_signal'] = macd_signal
        factors['macd_histogram'] = macd - macd_signal
        factors['macd_slope'] = macd.diff()
        
        # RSIç³»åˆ—
        returns = df['close'].pct_change()
        for period in [6, 14, 21]:
            gain = returns.where(returns > 0, 0)
            loss = -returns.where(returns < 0, 0)
            avg_gain = gain.rolling(period).mean()
            avg_loss = loss.rolling(period).mean()
            rs = avg_gain / avg_loss
            factors[f'rsi_{period}'] = 100 - (100 / (1 + rs))
            factors[f'rsi_slope_{period}'] = factors[f'rsi_{period}'].diff()
        
        # ATRå’Œç›¸å…³æŒ‡æ ‡
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift(1))
        low_close = np.abs(df['low'] - df['close'].shift(1))
        ranges = np.maximum(high_low, np.maximum(high_close, low_close))
        factors['atr'] = ranges.rolling(14).mean()
        factors['atr_ratio'] = factors['atr'] / df['close']
        factors['efficiency_ratio'] = abs(df['close'] - df['close'].shift(20)) / ranges.rolling(20).sum()
        
        # å¸ƒæ—å¸¦æŒ‡æ ‡
        for period in [10, 20]:
            sma = df['close'].rolling(period).mean()
            std = df['close'].rolling(period).std()
            factors[f'bb_upper_{period}'] = sma + 2 * std
            factors[f'bb_lower_{period}'] = sma - 2 * std
            factors[f'bb_width_{period}'] = (factors[f'bb_upper_{period}'] - factors[f'bb_lower_{period}']) / sma
            factors[f'bb_position_{period}'] = (df['close'] - factors[f'bb_lower_{period}']) / (factors[f'bb_upper_{period}'] - factors[f'bb_lower_{period}'])
        
        # è¶‹åŠ¿å¼ºåº¦æŒ‡æ ‡
        for period in [10, 20]:
            factors[f'trend_strength_{period}'] = abs(df['close'] - df['close'].shift(period)) / ranges.rolling(period).sum()
        
        return factors
    
    def _calculate_microstructure_factors(self, df: pd.DataFrame) -> Dict:
        """å¸‚åœºå¾®è§‚ç»“æ„å› å­"""
        factors = {}
        
        # æ—¥å†…è¡Œä¸ºå› å­
        factors['intraday_return'] = (df['close'] - df['open']) / df['open']
        factors['overnight_return'] = (df['open'] - df['close'].shift(1)) / df['close'].shift(1)
        factors['high_low_ratio'] = (df['high'] - df['low']) / df['close']
        
        # å½±çº¿åˆ†æ
        factors['upper_shadow'] = (df['high'] - np.maximum(df['open'], df['close'])) / df['close']
        factors['lower_shadow'] = (np.minimum(df['open'], df['close']) - df['low']) / df['close']
        factors['body_ratio'] = abs(df['close'] - df['open']) / (df['high'] - df['low'])
        
        # è·³ç©ºåˆ†æ
        factors['gap'] = (df['open'] - df['close'].shift(1)) / df['close'].shift(1)
        factors['gap_fill'] = np.where(
            factors['gap'] > 0,
            np.minimum(0, (df['low'] - df['close'].shift(1)) / df['close'].shift(1)),
            np.maximum(0, (df['high'] - df['close'].shift(1)) / df['close'].shift(1))
        )
        
        # ä»·æ ¼å†²å‡»æ¨¡å‹
        returns = df['close'].pct_change()
        factors['price_impact'] = returns / np.log(df['vol'] + 1)
        factors['amihud_illiquidity'] = abs(returns) / (df['amount'] / 1e8)  # AmihudéæµåŠ¨æ€§æŒ‡æ ‡
        
        return factors
    
    def _calculate_volume_price_factors(self, df: pd.DataFrame) -> Dict:
        """é‡ä»·å…³ç³»å› å­"""
        factors = {}
        
        returns = df['close'].pct_change()
        volume_change = df['vol'].pct_change()
        
        # é‡ä»·ç›¸å…³æ€§
        for period in [5, 10, 20]:
            factors[f'volume_price_corr_{period}'] = returns.rolling(period).corr(volume_change)
            factors[f'volume_return_corr_{period}'] = returns.rolling(period).corr(df['vol'])
        
        # æˆäº¤é‡æŒ‡æ ‡
        for period in [5, 10, 20]:
            factors[f'volume_ma_{period}'] = df['vol'].rolling(period).mean()
            factors[f'volume_ratio_{period}'] = df['vol'] / factors[f'volume_ma_{period}']
            factors[f'volume_std_{period}'] = df['vol'].rolling(period).std()
            factors[f'volume_cv_{period}'] = factors[f'volume_std_{period}'] / factors[f'volume_ma_{period}']
        
        # èµ„é‡‘æµæŒ‡æ ‡
        typical_price = (df['high'] + df['low'] + df['close']) / 3
        money_flow = typical_price * df['vol']
        
        positive_flow = money_flow.where(typical_price > typical_price.shift(1), 0)
        negative_flow = money_flow.where(typical_price < typical_price.shift(1), 0)
        
        for period in [14, 21]:
            pos_flow_sum = positive_flow.rolling(period).sum()
            neg_flow_sum = negative_flow.rolling(period).sum()
            factors[f'mfi_{period}'] = 100 - (100 / (1 + pos_flow_sum / neg_flow_sum))
        
        # OBVåŠå…¶å˜ç§
        factors['obv'] = (np.sign(returns) * df['vol']).cumsum()
        factors['obv_ma_10'] = factors['obv'].rolling(10).mean()
        factors['obv_slope'] = factors['obv'].diff(5)
        
        # é‡ä»·è¶‹åŠ¿æŒ‡æ ‡
        factors['volume_price_trend'] = ((typical_price - typical_price.shift(1)) / typical_price.shift(1) * df['vol']).cumsum()
        
        # æˆäº¤é¢ç›¸å…³
        factors['turnover_rate'] = df.get('turnover_rate', df['vol'] / 1e8)  # ç®€åŒ–å¤„ç†
        factors['amount_ma_5'] = df['amount'].rolling(5).mean()
        factors['amount_ratio'] = df['amount'] / factors['amount_ma_5']
        
        return factors
    
    def analyze_factor_effectiveness(self, factor_df: pd.DataFrame, return_period: int = 20) -> Dict:
        """
        åˆ†æå› å­æœ‰æ•ˆæ€§
        """
        print(f"å¼€å§‹åˆ†æå› å­æœ‰æ•ˆæ€§ï¼ˆé¢„æµ‹{return_period}æ—¥æ”¶ç›Šç‡ï¼‰...")
        
        target_col = f'future_return_{return_period}d'
        if target_col not in factor_df.columns:
            print(f"âš ï¸ ç¼ºå°‘ç›®æ ‡åˆ—: {target_col}")
            return {}
        
        future_returns = factor_df[target_col].dropna()
        if len(future_returns) < 30:
            print("âš ï¸ æœ‰æ•ˆæ ·æœ¬ä¸è¶³")
            return {}
        
        # è·å–å› å­åˆ—
        factor_columns = [col for col in factor_df.columns 
                         if col not in ['trade_date', 'close'] and not col.startswith('future_return')]
        
        factor_data = factor_df[factor_columns].loc[future_returns.index]
        
        # çº¿æ€§åˆ†æ
        linear_results = self._linear_factor_analysis(factor_data, future_returns)
        
        # æœºå™¨å­¦ä¹ åˆ†æ
        ml_results = {}
        if ML_AVAILABLE and len(future_returns) > 50:
            ml_results = self._ml_factor_analysis(factor_data, future_returns)
        
        # ç»¼åˆè¯„åˆ†
        final_scores = self._combine_factor_scores(linear_results, ml_results)
        
        # é€‰æ‹©æœ€ä½³å› å­
        selected_factors = self._select_best_factors(final_scores, factor_data)
        
        return {
            'linear_results': linear_results,
            'ml_results': ml_results,
            'final_scores': final_scores,
            'selected_factors': selected_factors,
            'summary_stats': {
                'total_factors': len(factor_columns),
                'valid_samples': len(future_returns),
                'target_std': future_returns.std(),
                'target_mean': future_returns.mean()
            }
        }
    
    def _linear_factor_analysis(self, factor_data: pd.DataFrame, returns: pd.Series) -> Dict:
        """çº¿æ€§å› å­åˆ†æ"""
        results = {}
        
        for factor_name in factor_data.columns:
            factor_values = factor_data[factor_name].fillna(0)
            
            if factor_values.std() == 0:  # å¸¸æ•°å› å­
                continue
            
            # ICè®¡ç®—
            ic = factor_values.corr(returns)
            rank_ic = factor_values.rank().corr(returns.rank())
            
            # åˆ†ç»„å›æµ‹
            try:
                factor_quantiles = pd.qcut(factor_values, 5, duplicates='drop')
                group_returns = returns.groupby(factor_quantiles).mean()
                
                if len(group_returns) >= 3:
                    # å¤šç©ºæ”¶ç›Š
                    long_short_return = group_returns.iloc[-1] - group_returns.iloc[0]
                    
                    # å•è°ƒæ€§
                    monotonic_up = sum(group_returns.iloc[i+1] >= group_returns.iloc[i] 
                                     for i in range(len(group_returns)-1))
                    monotonic_down = sum(group_returns.iloc[i+1] <= group_returns.iloc[i] 
                                       for i in range(len(group_returns)-1))
                    monotonicity = max(monotonic_up, monotonic_down) / (len(group_returns) - 1)
                else:
                    long_short_return = 0
                    monotonicity = 0
            except:
                long_short_return = 0
                monotonicity = 0
            
            results[factor_name] = {
                'ic': ic if not np.isnan(ic) else 0,
                'rank_ic': rank_ic if not np.isnan(rank_ic) else 0,
                'long_short_return': long_short_return,
                'monotonicity': monotonicity,
                'linear_score': abs(ic) * 0.5 + abs(rank_ic) * 0.3 + monotonicity * 0.2
            }
        
        return results
    
    def _ml_factor_analysis(self, factor_data: pd.DataFrame, returns: pd.Series) -> Dict:
        """æœºå™¨å­¦ä¹ å› å­åˆ†æ"""
        try:
            # æ•°æ®é¢„å¤„ç†
            clean_data = factor_data.fillna(0)
            
            # éšæœºæ£®æ—åˆ†æ
            rf = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=8)
            rf.fit(clean_data, returns)
            
            feature_importance = rf.feature_importances_
            model_r2 = rf.score(clean_data, returns)
            
            results = {}
            for i, factor_name in enumerate(clean_data.columns):
                results[factor_name] = {
                    'feature_importance': feature_importance[i],
                    'model_r2': model_r2,
                    'ml_score': feature_importance[i]
                }
            
            return results
            
        except Exception as e:
            print(f"âš ï¸ æœºå™¨å­¦ä¹ åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _combine_factor_scores(self, linear_results: Dict, ml_results: Dict) -> Dict:
        """ç»¼åˆå› å­è¯„åˆ†"""
        final_scores = {}
        
        all_factors = set(linear_results.keys()) | set(ml_results.keys())
        
        for factor in all_factors:
            linear_score = linear_results.get(factor, {}).get('linear_score', 0)
            ml_score = ml_results.get(factor, {}).get('ml_score', 0)
            
            # åŠ¨æ€æƒé‡
            if ml_score > 0:
                final_score = 0.6 * linear_score + 0.4 * ml_score
            else:
                final_score = linear_score
            
            final_scores[factor] = {
                'linear_component': linear_score,
                'ml_component': ml_score,
                'final_score': final_score
            }
        
        return final_scores
    
    def _select_best_factors(self, final_scores: Dict, factor_data: pd.DataFrame, 
                           max_factors: int = 15) -> List[str]:
        """é€‰æ‹©æœ€ä½³å› å­ç»„åˆ"""
        # æ’åº
        sorted_factors = sorted(final_scores.items(), 
                               key=lambda x: x[1]['final_score'], reverse=True)
        
        selected = []
        correlation_matrix = factor_data.corr()
        
        for factor_name, scores in sorted_factors:
            if len(selected) >= max_factors:
                break
                
            if factor_name not in correlation_matrix.columns:
                continue
            
            # ç›¸å…³æ€§æ£€æŸ¥
            max_corr = 0
            if selected:
                corrs = [abs(correlation_matrix.loc[factor_name, sel_factor]) 
                        for sel_factor in selected 
                        if sel_factor in correlation_matrix.columns]
                max_corr = max(corrs) if corrs else 0
            
            if max_corr < 0.8:  # ç›¸å…³æ€§é˜ˆå€¼
                selected.append(factor_name)
        
        return selected
    
    def run_full_analysis(self, stock_code: str, start_date: str, end_date: str) -> Dict:
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
        """
        print(f"ğŸš€ å¼€å§‹å®Œæ•´å› å­åˆ†æ: {stock_code}")
        print("=" * 60)
        
        # 1. è·å–æ•°æ®
        print("Step 1: è·å–è‚¡ç¥¨æ•°æ®...")
        df = self.get_stock_data(stock_code, start_date, end_date)
        
        if df.empty:
            print("âŒ æ— æ³•è·å–è‚¡ç¥¨æ•°æ®")
            return {}
        
        print(f"âœ… æ•°æ®æ—¶é—´èŒƒå›´: {df['trade_date'].min()} åˆ° {df['trade_date'].max()}")
        print(f"âœ… æ•°æ®æ¡æ•°: {len(df)}")
        
        # 2. è®¡ç®—å› å­
        print("\nStep 2: è®¡ç®—å¢å¼ºå› å­...")
        factor_df = self.calculate_enhanced_factors(df)
        
        if factor_df.empty:
            print("âŒ å› å­è®¡ç®—å¤±è´¥")
            return {}
        
        # 3. å› å­åˆ†æ
        print("\nStep 3: å› å­æœ‰æ•ˆæ€§åˆ†æ...")
        analysis_results = self.analyze_factor_effectiveness(factor_df, return_period=20)
        
        if not analysis_results:
            print("âŒ å› å­åˆ†æå¤±è´¥")
            return {}
        
        # 4. ç»“æœå±•ç¤º
        print("\nStep 4: åˆ†æç»“æœ...")
        self._display_analysis_results(analysis_results)
        
        # 5. ä¿å­˜ç»“æœ
        print("\nStep 5: ä¿å­˜ç»“æœ...")
        self._save_analysis_results(stock_code, factor_df, analysis_results)
        
        return {
            'stock_data': df,
            'factor_data': factor_df,
            'analysis_results': analysis_results
        }
    
    def _display_analysis_results(self, results: Dict):
        """å±•ç¤ºåˆ†æç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“Š å› å­åˆ†æç»“æœ")
        print("="*60)
        
        stats = results['summary_stats']
        print(f"åˆ†æç»Ÿè®¡:")
        print(f"  - æ€»å› å­æ•°: {stats['total_factors']}")
        print(f"  - æœ‰æ•ˆæ ·æœ¬: {stats['valid_samples']}")
        print(f"  - ç›®æ ‡æ”¶ç›Šç‡å‡å€¼: {stats['target_mean']:.4f}")
        print(f"  - ç›®æ ‡æ”¶ç›Šç‡æ ‡å‡†å·®: {stats['target_std']:.4f}")
        
        # æ˜¾ç¤ºå‰10ä¸ªæœ€ä½³å› å­
        top_factors = sorted(results['final_scores'].items(), 
                           key=lambda x: x[1]['final_score'], reverse=True)[:10]
        
        print(f"\nğŸ† Top 10 æœ€ä½³å› å­:")
        for i, (factor_name, scores) in enumerate(top_factors, 1):
            linear_data = results['linear_results'].get(factor_name, {})
            print(f"{i:2d}. {factor_name:<30} | ç»¼åˆå¾—åˆ†: {scores['final_score']:.4f} "
                  f"| IC: {linear_data.get('ic', 0):.4f}")
        
        print(f"\nâœ… æœ€ç»ˆé€‰æ‹©å› å­ ({len(results['selected_factors'])}ä¸ª):")
        for i, factor in enumerate(results['selected_factors'], 1):
            score = results['final_scores'][factor]['final_score']
            print(f"{i:2d}. {factor:<30} | å¾—åˆ†: {score:.4f}")
    
    def _save_analysis_results(self, stock_code: str, factor_df: pd.DataFrame, results: Dict):
        """ä¿å­˜åˆ†æç»“æœ"""
        # ä¿å­˜å› å­æ•°æ®
        factor_file = f"{stock_code}_enhanced_factors_real.csv"
        factor_df.to_csv(factor_file, index=False)
        
        # ä¿å­˜åˆ†æç»“æœ
        results_file = f"{stock_code}_factor_analysis_real.json"
        
        # ç®€åŒ–ç»“æœç”¨äºJSONåºåˆ—åŒ–
        simplified_results = {
            'selected_factors': results['selected_factors'],
            'top_10_factors': {
                factor: scores for factor, scores in 
                sorted(results['final_scores'].items(), 
                       key=lambda x: x[1]['final_score'], reverse=True)[:10]
            },
            'summary_stats': results['summary_stats']
        }
        
        import json
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(simplified_results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å› å­æ•°æ®å·²ä¿å­˜: {factor_file}")
        print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜: {results_file}")

def main():
    """ä¸»å‡½æ•°æ¼”ç¤º"""
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = RealDataFactorSystem(
        tushare_token='b34d8920b99b43d48df7e792a4708a29f868feeee30d9c84b54bf065',
        data_dir='./factor_data'
    )
    
    # åˆ†æè‚¡ç¥¨
    test_stocks = ['000001.SZ', '600036.SH']  # å¹³å®‰é“¶è¡Œã€æ‹›å•†é“¶è¡Œ
    
    for stock_code in test_stocks:
        try:
            results = system.run_full_analysis(
                stock_code=stock_code,
                start_date='20230101',
                end_date='20240131'
            )
            
            if results:
                print(f"\nâœ… {stock_code} åˆ†æå®Œæˆ")
            else:
                print(f"\nâŒ {stock_code} åˆ†æå¤±è´¥")
                
        except Exception as e:
            print(f"\nâŒ {stock_code} åˆ†æå¼‚å¸¸: {e}")
            continue
    
    print("\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()